import pandas as pd
from sklearn.model_selection import train_test_split
from rdkit import Chem
from rdkit.Chem.Scaffolds import MurckoScaffold
import numpy as np
import abc
import gin
import logging
import hashlib


class DataSplitterBase(abc.ABC):
    """
    Abstract base class for data splitting strategies.

    Provides interface for splitting molecular datasets into training and testing sets
    with various strategies (random, scaffold-based, stratified, etc.).

    :param test_size: Proportion of dataset to include in test split
    :type test_size: float
    :param random_state: Random seed for reproducibility
    :type random_state: int
    :ivar test_size: Configured test set proportion
    :type test_size: float
    :ivar random_state: Configured random seed
    :type random_state: int
    """

    def __init__(self, test_size=0.2, random_state=42):
        self.test_size = test_size
        self.random_state = random_state

    @abc.abstractmethod
    def split(self, X: pd.Series, y: pd.Series):
        """
        Split the dataset into training and testing sets.

        :param X: SMILES strings or molecular identifiers
        :type X: pd.Series
        :param y: Target labels or values
        :type y: pd.Series
        :return: Training and testing indices or data splits
        :rtype: Tuple or similar split representation
        """
        pass

    @abc.abstractmethod
    def get_hashable_params_values(self) -> list:
        """
        Return parameters for hashing/caching purposes.

        :return: List of parameter values that uniquely identify this splitter configuration
        :rtype: list
        """
        pass

    @property
    @abc.abstractmethod
    def name(self):
        """
        Human-readable splitter name.

        :return: Descriptive name for this splitting strategy
        :rtype: str
        """
        pass

    @staticmethod
    def _get_number_of_classes(labels):
        if not isinstance(labels, pd.Series):
            labels = pd.Series(labels)
        return len(labels.unique())

    def get_friendly_name(
        self,
        multiple_friendly_names: list[str],
    ) -> str:
        """
        Generate human-readable name for split from component dataset names.

        Combines abbreviated versions of input dataset names with splitter cache key.
        Each dataset name is truncated to first 3 characters of its first 3 underscore-separated parts.

        :param multiple_friendly_names: List of dataset friendly names being split
        :type multiple_friendly_names: list[str]
        :return: Combined friendly name for this split
        :rtype: str
        """
        generated_name_chunks: list[str] = [
            "_".join([part[:3] for part in name.split("_")[:3]])
            for name in multiple_friendly_names
        ]
        generated_name_chunks.append(self.get_cache_key())

        return "_".join(generated_name_chunks)

    def get_cache_key(self):
        """
        Generate a 5-character cache key from splitter parameters.

        Creates identifier by MD5 hashing the parameter values and combining
        with splitter name.

        :return: Cache key in format '{name}_{hash[:5]}'
        :rtype: str
        """
        params_values = self.get_hashable_params_values()
        params_values = str(params_values).encode("utf-8")
        hash_string = hashlib.md5(params_values).hexdigest()
        return f"{self.name}_{hash_string[:5]}"


@gin.configurable
class RandomSplitter(DataSplitterBase):
    """
    Splits the dataset into training and testing sets using random sampling.
    The split can be stratified based on the target variable if specified.
    """

    def __init__(
        self,
        test_size=0.2,
        random_state=42,
        stratify=None,
    ):
        super().__init__(test_size=test_size, random_state=random_state)
        self.stratify = stratify

    @property
    def name(self):
        return "random"

    def get_hashable_params_values(self):
        return [self.test_size, self.random_state, self.stratify]

    def split(
        self, X: pd.Series, y: pd.Series
    ) -> tuple[pd.Series, pd.Series, pd.Series, pd.Series]:

        if self.stratify:
            if self._get_number_of_classes(y) >= 5:
                logging.warning(
                    f"Detected {self._get_number_of_classes(y)} unique classes of {len(y)} samples. "
                    "Make sure you are not stratifying on a continuous target variable!"
                )
            labels_to_stratify = y
        else:
            labels_to_stratify = None

        X_train, X_test, y_train, y_test = train_test_split(
            X,
            y,
            test_size=self.test_size,
            random_state=self.random_state,
            stratify=labels_to_stratify,
        )
        return X_train, X_test, y_train, y_test


@gin.configurable
class ScaffoldSplitter(DataSplitterBase):
    """
    Splits the dataset into training and testing sets based on molecular (Murcko) scaffolds.
    This ensures that molecules with similar scaffolds are not split between training and testing sets,
    providing a more challenging and realistic task for model evaluation.
    """

    def __init__(self, test_size=0.2, random_state=42):
        super().__init__(test_size=test_size, random_state=random_state)

    @property
    def name(self):
        return "scaffold"

    def get_hashable_params_values(self):
        return [self.test_size, self.random_state]

    def split(
        self, X: pd.Series, y: pd.Series
    ) -> tuple[pd.Series, pd.Series, pd.Series, pd.Series]:
        scaffolds = {}

        # Group molecules by their scaffolds, storing indices of molecules with the same scaffold
        # in a dictionary with scaffold SMILES as keys.
        for i, smi in enumerate(X):
            mol = Chem.MolFromSmiles(smi)
            scaffold = MurckoScaffold.GetScaffoldForMol(mol)
            scaffold_smiles = Chem.MolToSmiles(scaffold)
            if scaffold_smiles not in scaffolds:
                scaffolds[scaffold_smiles] = []
            scaffolds[scaffold_smiles].append(i)

        # Shuffle the scaffold sets to ensure randomness in the split
        scaffold_sets = list(scaffolds.values())
        np.random.seed(self.random_state)
        np.random.shuffle(scaffold_sets)

        # Split the scaffold sets into training and testing sets
        train_indices, test_indices = [], []
        n_test = int(len(X) * self.test_size)
        for scaffold_set in scaffold_sets:
            if len(test_indices) + len(scaffold_set) <= n_test:
                test_indices.extend(scaffold_set)
            else:
                train_indices.extend(scaffold_set)

        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]
        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]
        return X_train, X_test, y_train, y_test
